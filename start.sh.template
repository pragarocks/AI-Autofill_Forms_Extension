#!/bin/bash

echo "========================================"
echo "   AI AutoFill Browser Extension"
echo "========================================"
echo

# ========================================
# CONFIGURATION - EDIT YOUR API KEY HERE
# ========================================
# Replace "YOUR_API_KEY_HERE" with your actual Google Gemini API key
# Get your API key from: https://makersuite.google.com/app/apikey
export GOOGLE_API_KEY="YOUR_API_KEY_HERE"

# ========================================
# ADVANCED CONFIGURATION (Optional)
# ========================================
# Set to "true" to enable local LLM (Hugging Face Transformers - NO cmake required!)
export LOCAL_LLM_ENABLED="true"

# Optional: Set local LLM model (will auto-download on first use)
# Options: distilgpt2 (~300MB), gpt2-medium (~1.4GB), microsoft/DialoGPT-medium (~1.5GB)
export LOCAL_LLM_MODEL="microsoft/DialoGPT-medium"

# To setup local LLM dependencies, run: python3 setup_local_llm.py

# ========================================
# EXTERNAL LLM CONFIGURATION (For powerful systems)
# ========================================
# Uncomment and configure for external LLM servers:

# LM Studio (recommended for external systems)
# export LM_STUDIO_URL="http://localhost:1234/v1"

# llama.cpp server
# export LLAMACPP_URL="http://localhost:8080"

# Ollama
# export OLLAMA_URL="http://localhost:11434"

# Text Generation WebUI (oobabooga)
# export TEXTGEN_URL="http://localhost:5000/v1"

# Custom external LLM endpoint
# export CUSTOM_LLM_URL="http://your-server:port/v1"

echo "Starting AI AutoFill server..."
echo
echo "Configuration:"
echo "- Google API Key: $GOOGLE_API_KEY"
echo "- Local LLM Enabled: $LOCAL_LLM_ENABLED"
echo
echo "Server will be available at: http://localhost:3000"
echo "Extension files at: http://localhost:3000/extension"
echo "Test form at: http://localhost:3000/test-form"
echo
echo "Press Ctrl+C to stop the server"
echo

# Start the server
node src/main.js 