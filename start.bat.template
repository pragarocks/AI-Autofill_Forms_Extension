@echo off
echo ========================================
echo    AI AutoFill Browser Extension
echo ========================================
echo.

REM ========================================
REM CONFIGURATION - EDIT YOUR API KEY HERE
REM ========================================
REM Replace "YOUR_API_KEY_HERE" with your actual Google Gemini API key
REM Get your API key from: https://makersuite.google.com/app/apikey
set GOOGLE_API_KEY=YOUR_API_KEY_HERE

REM ========================================
REM ADVANCED CONFIGURATION (Optional)
REM ========================================
REM Set to "true" to enable local LLM (Hugging Face Transformers - NO cmake required!)
set LOCAL_LLM_ENABLED=true

REM Optional: Set local LLM model (will auto-download on first use)
REM Options: distilgpt2 (~300MB), gpt2-medium (~1.4GB), microsoft/DialoGPT-medium (~1.5GB)
set LOCAL_LLM_MODEL=microsoft/DialoGPT-medium

REM To setup local LLM dependencies, run: python setup_local_llm.py

REM ========================================
REM EXTERNAL LLM CONFIGURATION (For powerful systems)
REM ========================================
REM Uncomment and configure for external LLM servers:

REM LM Studio (recommended for external systems)
REM set LM_STUDIO_URL=http://localhost:1234/v1

REM llama.cpp server
REM set LLAMACPP_URL=http://localhost:8080

REM Ollama 
REM set OLLAMA_URL=http://localhost:11434

REM Text Generation WebUI (oobabooga)
REM set TEXTGEN_URL=http://localhost:5000/v1

REM Custom external LLM endpoint
REM set CUSTOM_LLM_URL=http://your-server:port/v1

echo Starting AI AutoFill server...
echo.
echo Configuration:
echo - Google API Key: %GOOGLE_API_KEY%
echo - Local LLM Enabled: %LOCAL_LLM_ENABLED%
echo.
echo Server will be available at: http://localhost:3000
echo Extension files at: http://localhost:3000/extension
echo Test form at: http://localhost:3000/test-form
echo.
echo Press Ctrl+C to stop the server
echo.

REM Start the server
node src/main.js

pause 